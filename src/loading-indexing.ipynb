{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "with open(\"/home/ltnga/LawVN-Instructction-Gen/src/data/data.json\") as f:\n",
    "    all_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(text=doc) for doc in documents]\n",
    "\n",
    "# Now create and use the TokenTextSplitter\n",
    "base_node_parser = TokenTextSplitter(\n",
    "    chunk_overlap=50,\n",
    "    chunk_size=300,\n",
    "    separator=\" \",\n",
    "    backup_separators=[\"__\", \"..\", \"--\"],\n",
    "    include_prev_next_rel=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"qducnguyen/vietnamese-bi-encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_node_parser = TokenTextSplitter( \n",
    "                                chunk_overlap=0,\n",
    "                                chunk_size=1000,\n",
    "                                separator=\" \",\n",
    "                                backup_separators=[\"__\", \"..\", \"--\"],\n",
    "                                include_prev_next_rel=False\n",
    "                                )\n",
    "\n",
    "\n",
    "base_nodes = base_node_parser.get_nodes_from_documents(documents,\n",
    "                                                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_nodes[3].text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save as parent parquet \n",
    "# import os\n",
    "# from datasets import Dataset\n",
    "\n",
    "# dataset = Dataset.from_list([node.to_dict() for node in base_nodes])\n",
    "\n",
    "# with open(os.path.join(\"/home/s/ducnq/law-rag/data/hf\", \"parent_nodes.parquet\"), \"wb\") as fOut:\n",
    "#     dataset.to_parquet(fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Child nodes\n",
    "from tqdm import tqdm\n",
    "for base_node in tqdm(base_nodes):\n",
    "    base_node.metadata[\"parent_text\"] = base_node.text\n",
    "    # base_node.text = ViTokenizer.tokenize(base_node.text.lower())\n",
    "    base_node.excluded_embed_metadata_keys.append(\"parent_text\")\n",
    "    base_node.excluded_llm_metadata_keys.append(\"parent_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_node_parser= SentenceSplitter(\n",
    "                    chunk_size=100,\n",
    "                    chunk_overlap=0,\n",
    "                    separator=\" \",\n",
    "                    include_prev_next_rel=False,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_nodes = child_node_parser.get_nodes_from_documents(base_nodes,\n",
    "                                                         show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(child_nodes[0].text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from llama_index.core.schema import NodeRelationship\n",
    "\n",
    "for child_node in tqdm(child_nodes):\n",
    "    child_node.text = ViTokenizer.tokenize(child_node.text.lower())\n",
    "    try:\n",
    "        del child_node.relationships[NodeRelationship.SOURCE].metadata\n",
    "    except AttributeError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(child_nodes), child_nodes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_nodes[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save as child parquet \n",
    "# import os\n",
    "# from datasets import Dataset\n",
    "\n",
    "# dataset = Dataset.from_list([node.to_dict() for node in child_nodes])\n",
    "\n",
    "# with open(os.path.join(\"/home/s/ducnq/law-rag/data/hf\", \"child_nodes.parquet\"), \"wb\") as fOut:\n",
    "#     dataset.to_parquet(fOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to folder to HF \n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "REPO_ID = \"bkai-foundation-models/TVPL\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "api = HfApi()\n",
    "\n",
    "# api.create_repo(\n",
    "#     repo_id=REPO_ID,\n",
    "#     private=True,\n",
    "#     repo_type=REPO_TYPE,\n",
    "#     exist_ok=False\n",
    "# )\n",
    "\n",
    "\n",
    "api.upload_folder(folder_path=\"/home/s/ducnq/law-rag/data/hf\",\n",
    "                  repo_id=REPO_ID,\n",
    "                  repo_type=REPO_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.llama_cpp.llama_utils import messages_to_prompt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "import weaviate\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "\n",
    "WEAVIATE_URL = \"https://jd11sxlqap7tdknwzega.c0.asia-southeast1.gcp.weaviate.cloud\"\n",
    "weaviate_api_key = \"93M51uT7bsG5EMnfL5z78woitWLg7XuAn4ps\"\n",
    "DATA_COLLECTION = \"ND168\"\n",
    "DEVICE = \"cuda:0\"\n",
    "MODEL_NAME = \"qducnguyen/vietnamese-bi-encoder\"\n",
    "embed_model = HuggingFaceEmbedding(model_name=MODEL_NAME, \n",
    "                                   max_length=256,\n",
    "                                   device=DEVICE)\n",
    "\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,\n",
    "    auth_credentials=Auth.api_key(weaviate_api_key),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = WeaviateVectorStore(weaviate_client=client,\n",
    "                                   index_name=DATA_COLLECTION)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(child_nodes, \n",
    "                         storage_context=storage_context, \n",
    "                         embed_model=embed_model,\n",
    "                         insert_batch_size=32768,\n",
    "                         show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "from pyvi import ViTokenizer\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "base_retriever = index.as_retriever(vector_store_query_mode=\"hybrid\",\n",
    "                                    similarity_top_k=100, \n",
    "                                    alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_QUESTION = \"đi xe máy không đội mũ bảo hiểm bị phạt bao nhiêu tiền?\"\n",
    "retrievals = base_retriever.retrieve(\n",
    "    ViTokenizer.tokenize(TEST_QUESTION.lower())\n",
    ")\n",
    "\n",
    "for n in retrievals[:5]:\n",
    "    display_source_node(n, source_length=1000, show_source_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
